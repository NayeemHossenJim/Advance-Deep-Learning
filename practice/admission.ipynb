{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15009839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f8f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Chance of Admit ",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c98db699-a4d9-473f-9723-a1d8906e3a72",
       "rows": [
        [
         "0",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1",
         "0.92"
        ],
        [
         "1",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1",
         "0.76"
        ],
        [
         "2",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1",
         "0.72"
        ],
        [
         "3",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1",
         "0.8"
        ],
        [
         "4",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0",
         "0.65"
        ],
        [
         "5",
         "330",
         "115",
         "5",
         "4.5",
         "3.0",
         "9.34",
         "1",
         "0.9"
        ],
        [
         "6",
         "321",
         "109",
         "3",
         "3.0",
         "4.0",
         "8.2",
         "1",
         "0.75"
        ],
        [
         "7",
         "308",
         "101",
         "2",
         "3.0",
         "4.0",
         "7.9",
         "0",
         "0.68"
        ],
        [
         "8",
         "302",
         "102",
         "1",
         "2.0",
         "1.5",
         "8.0",
         "0",
         "0.5"
        ],
        [
         "9",
         "323",
         "108",
         "3",
         "3.5",
         "3.0",
         "8.6",
         "0",
         "0.45"
        ],
        [
         "10",
         "325",
         "106",
         "3",
         "3.5",
         "4.0",
         "8.4",
         "1",
         "0.52"
        ],
        [
         "11",
         "327",
         "111",
         "4",
         "4.0",
         "4.5",
         "9.0",
         "1",
         "0.84"
        ],
        [
         "12",
         "328",
         "112",
         "4",
         "4.0",
         "4.5",
         "9.1",
         "1",
         "0.78"
        ],
        [
         "13",
         "307",
         "109",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1",
         "0.62"
        ],
        [
         "14",
         "311",
         "104",
         "3",
         "3.5",
         "2.0",
         "8.2",
         "1",
         "0.61"
        ],
        [
         "15",
         "314",
         "105",
         "3",
         "3.5",
         "2.5",
         "8.3",
         "0",
         "0.54"
        ],
        [
         "16",
         "317",
         "107",
         "3",
         "4.0",
         "3.0",
         "8.7",
         "0",
         "0.66"
        ],
        [
         "17",
         "319",
         "106",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1",
         "0.65"
        ],
        [
         "18",
         "318",
         "110",
         "3",
         "4.0",
         "3.0",
         "8.8",
         "0",
         "0.63"
        ],
        [
         "19",
         "303",
         "102",
         "3",
         "3.5",
         "3.0",
         "8.5",
         "0",
         "0.62"
        ],
        [
         "20",
         "312",
         "107",
         "3",
         "3.0",
         "2.0",
         "7.9",
         "1",
         "0.64"
        ],
        [
         "21",
         "325",
         "114",
         "4",
         "3.0",
         "2.0",
         "8.4",
         "0",
         "0.7"
        ],
        [
         "22",
         "328",
         "116",
         "5",
         "5.0",
         "5.0",
         "9.5",
         "1",
         "0.94"
        ],
        [
         "23",
         "334",
         "119",
         "5",
         "5.0",
         "4.5",
         "9.7",
         "1",
         "0.95"
        ],
        [
         "24",
         "336",
         "119",
         "5",
         "4.0",
         "3.5",
         "9.8",
         "1",
         "0.97"
        ],
        [
         "25",
         "340",
         "120",
         "5",
         "4.5",
         "4.5",
         "9.6",
         "1",
         "0.94"
        ],
        [
         "26",
         "322",
         "109",
         "5",
         "4.5",
         "3.5",
         "8.8",
         "0",
         "0.76"
        ],
        [
         "27",
         "298",
         "98",
         "2",
         "1.5",
         "2.5",
         "7.5",
         "1",
         "0.44"
        ],
        [
         "28",
         "295",
         "93",
         "1",
         "2.0",
         "2.0",
         "7.2",
         "0",
         "0.46"
        ],
        [
         "29",
         "310",
         "99",
         "2",
         "1.5",
         "2.0",
         "7.3",
         "0",
         "0.54"
        ],
        [
         "30",
         "300",
         "97",
         "2",
         "3.0",
         "3.0",
         "8.1",
         "1",
         "0.65"
        ],
        [
         "31",
         "327",
         "103",
         "3",
         "4.0",
         "4.0",
         "8.3",
         "1",
         "0.74"
        ],
        [
         "32",
         "338",
         "118",
         "4",
         "3.0",
         "4.5",
         "9.4",
         "1",
         "0.91"
        ],
        [
         "33",
         "340",
         "114",
         "5",
         "4.0",
         "4.0",
         "9.6",
         "1",
         "0.9"
        ],
        [
         "34",
         "331",
         "112",
         "5",
         "4.0",
         "5.0",
         "9.8",
         "1",
         "0.94"
        ],
        [
         "35",
         "320",
         "110",
         "5",
         "5.0",
         "5.0",
         "9.2",
         "1",
         "0.88"
        ],
        [
         "36",
         "299",
         "106",
         "2",
         "4.0",
         "4.0",
         "8.4",
         "0",
         "0.64"
        ],
        [
         "37",
         "300",
         "105",
         "1",
         "1.0",
         "2.0",
         "7.8",
         "0",
         "0.58"
        ],
        [
         "38",
         "304",
         "105",
         "1",
         "3.0",
         "1.5",
         "7.5",
         "0",
         "0.52"
        ],
        [
         "39",
         "307",
         "108",
         "2",
         "4.0",
         "3.5",
         "7.7",
         "0",
         "0.48"
        ],
        [
         "40",
         "308",
         "110",
         "3",
         "3.5",
         "3.0",
         "8.0",
         "1",
         "0.46"
        ],
        [
         "41",
         "316",
         "105",
         "2",
         "2.5",
         "2.5",
         "8.2",
         "1",
         "0.49"
        ],
        [
         "42",
         "313",
         "107",
         "2",
         "2.5",
         "2.0",
         "8.5",
         "1",
         "0.53"
        ],
        [
         "43",
         "332",
         "117",
         "4",
         "4.5",
         "4.0",
         "9.1",
         "0",
         "0.87"
        ],
        [
         "44",
         "326",
         "113",
         "5",
         "4.5",
         "4.0",
         "9.4",
         "1",
         "0.91"
        ],
        [
         "45",
         "322",
         "110",
         "5",
         "5.0",
         "4.0",
         "9.1",
         "1",
         "0.88"
        ],
        [
         "46",
         "329",
         "114",
         "5",
         "4.0",
         "5.0",
         "9.3",
         "1",
         "0.86"
        ],
        [
         "47",
         "339",
         "119",
         "5",
         "4.5",
         "4.0",
         "9.7",
         "0",
         "0.89"
        ],
        [
         "48",
         "321",
         "110",
         "3",
         "3.5",
         "5.0",
         "8.85",
         "1",
         "0.82"
        ],
        [
         "49",
         "327",
         "111",
         "4",
         "3.0",
         "4.0",
         "8.4",
         "1",
         "0.78"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 400
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Admission_Predict.csv', usecols=['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research', 'Chance of Admit '])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1940fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Chance of Admit ', axis=1)\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a608931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "GRE Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOEFL Score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "University Rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SOP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LOR ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CGPA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Research",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3f5a8a97-a854-4f9e-941c-38a6bc4c3d9d",
       "rows": [
        [
         "0",
         "337",
         "118",
         "4",
         "4.5",
         "4.5",
         "9.65",
         "1"
        ],
        [
         "1",
         "324",
         "107",
         "4",
         "4.0",
         "4.5",
         "8.87",
         "1"
        ],
        [
         "2",
         "316",
         "104",
         "3",
         "3.0",
         "3.5",
         "8.0",
         "1"
        ],
        [
         "3",
         "322",
         "110",
         "3",
         "3.5",
         "2.5",
         "8.67",
         "1"
        ],
        [
         "4",
         "314",
         "103",
         "2",
         "2.0",
         "3.0",
         "8.21",
         "0"
        ],
        [
         "5",
         "330",
         "115",
         "5",
         "4.5",
         "3.0",
         "9.34",
         "1"
        ],
        [
         "6",
         "321",
         "109",
         "3",
         "3.0",
         "4.0",
         "8.2",
         "1"
        ],
        [
         "7",
         "308",
         "101",
         "2",
         "3.0",
         "4.0",
         "7.9",
         "0"
        ],
        [
         "8",
         "302",
         "102",
         "1",
         "2.0",
         "1.5",
         "8.0",
         "0"
        ],
        [
         "9",
         "323",
         "108",
         "3",
         "3.5",
         "3.0",
         "8.6",
         "0"
        ],
        [
         "10",
         "325",
         "106",
         "3",
         "3.5",
         "4.0",
         "8.4",
         "1"
        ],
        [
         "11",
         "327",
         "111",
         "4",
         "4.0",
         "4.5",
         "9.0",
         "1"
        ],
        [
         "12",
         "328",
         "112",
         "4",
         "4.0",
         "4.5",
         "9.1",
         "1"
        ],
        [
         "13",
         "307",
         "109",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1"
        ],
        [
         "14",
         "311",
         "104",
         "3",
         "3.5",
         "2.0",
         "8.2",
         "1"
        ],
        [
         "15",
         "314",
         "105",
         "3",
         "3.5",
         "2.5",
         "8.3",
         "0"
        ],
        [
         "16",
         "317",
         "107",
         "3",
         "4.0",
         "3.0",
         "8.7",
         "0"
        ],
        [
         "17",
         "319",
         "106",
         "3",
         "4.0",
         "3.0",
         "8.0",
         "1"
        ],
        [
         "18",
         "318",
         "110",
         "3",
         "4.0",
         "3.0",
         "8.8",
         "0"
        ],
        [
         "19",
         "303",
         "102",
         "3",
         "3.5",
         "3.0",
         "8.5",
         "0"
        ],
        [
         "20",
         "312",
         "107",
         "3",
         "3.0",
         "2.0",
         "7.9",
         "1"
        ],
        [
         "21",
         "325",
         "114",
         "4",
         "3.0",
         "2.0",
         "8.4",
         "0"
        ],
        [
         "22",
         "328",
         "116",
         "5",
         "5.0",
         "5.0",
         "9.5",
         "1"
        ],
        [
         "23",
         "334",
         "119",
         "5",
         "5.0",
         "4.5",
         "9.7",
         "1"
        ],
        [
         "24",
         "336",
         "119",
         "5",
         "4.0",
         "3.5",
         "9.8",
         "1"
        ],
        [
         "25",
         "340",
         "120",
         "5",
         "4.5",
         "4.5",
         "9.6",
         "1"
        ],
        [
         "26",
         "322",
         "109",
         "5",
         "4.5",
         "3.5",
         "8.8",
         "0"
        ],
        [
         "27",
         "298",
         "98",
         "2",
         "1.5",
         "2.5",
         "7.5",
         "1"
        ],
        [
         "28",
         "295",
         "93",
         "1",
         "2.0",
         "2.0",
         "7.2",
         "0"
        ],
        [
         "29",
         "310",
         "99",
         "2",
         "1.5",
         "2.0",
         "7.3",
         "0"
        ],
        [
         "30",
         "300",
         "97",
         "2",
         "3.0",
         "3.0",
         "8.1",
         "1"
        ],
        [
         "31",
         "327",
         "103",
         "3",
         "4.0",
         "4.0",
         "8.3",
         "1"
        ],
        [
         "32",
         "338",
         "118",
         "4",
         "3.0",
         "4.5",
         "9.4",
         "1"
        ],
        [
         "33",
         "340",
         "114",
         "5",
         "4.0",
         "4.0",
         "9.6",
         "1"
        ],
        [
         "34",
         "331",
         "112",
         "5",
         "4.0",
         "5.0",
         "9.8",
         "1"
        ],
        [
         "35",
         "320",
         "110",
         "5",
         "5.0",
         "5.0",
         "9.2",
         "1"
        ],
        [
         "36",
         "299",
         "106",
         "2",
         "4.0",
         "4.0",
         "8.4",
         "0"
        ],
        [
         "37",
         "300",
         "105",
         "1",
         "1.0",
         "2.0",
         "7.8",
         "0"
        ],
        [
         "38",
         "304",
         "105",
         "1",
         "3.0",
         "1.5",
         "7.5",
         "0"
        ],
        [
         "39",
         "307",
         "108",
         "2",
         "4.0",
         "3.5",
         "7.7",
         "0"
        ],
        [
         "40",
         "308",
         "110",
         "3",
         "3.5",
         "3.0",
         "8.0",
         "1"
        ],
        [
         "41",
         "316",
         "105",
         "2",
         "2.5",
         "2.5",
         "8.2",
         "1"
        ],
        [
         "42",
         "313",
         "107",
         "2",
         "2.5",
         "2.0",
         "8.5",
         "1"
        ],
        [
         "43",
         "332",
         "117",
         "4",
         "4.5",
         "4.0",
         "9.1",
         "0"
        ],
        [
         "44",
         "326",
         "113",
         "5",
         "4.5",
         "4.0",
         "9.4",
         "1"
        ],
        [
         "45",
         "322",
         "110",
         "5",
         "5.0",
         "4.0",
         "9.1",
         "1"
        ],
        [
         "46",
         "329",
         "114",
         "5",
         "4.0",
         "5.0",
         "9.3",
         "1"
        ],
        [
         "47",
         "339",
         "119",
         "5",
         "4.5",
         "4.0",
         "9.7",
         "0"
        ],
        [
         "48",
         "321",
         "110",
         "3",
         "3.5",
         "5.0",
         "8.85",
         "1"
        ],
        [
         "49",
         "327",
         "111",
         "4",
         "3.0",
         "4.0",
         "8.4",
         "1"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 400
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "395        324          110                  3  3.5   3.5  9.04         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "397        330          116                  4  5.0   4.5  9.45         1\n",
       "398        312          103                  3  3.5   4.0  8.78         0\n",
       "399        333          117                  4  5.0   4.0  9.66         1\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c08a23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76210664,  1.74697064,  0.79882862, ...,  1.16732114,\n",
       "         1.76481828,  0.90911166],\n",
       "       [ 0.62765641, -0.06763531,  0.79882862, ...,  1.16732114,\n",
       "         0.45515126,  0.90911166],\n",
       "       [-0.07046681, -0.56252785, -0.07660001, ...,  0.05293342,\n",
       "        -1.00563118,  0.90911166],\n",
       "       ...,\n",
       "       [ 1.15124883,  1.41704229,  0.79882862, ...,  1.16732114,\n",
       "         1.42900622,  0.90911166],\n",
       "       [-0.41952842, -0.72749202, -0.07660001, ...,  0.61012728,\n",
       "         0.30403584, -1.09997489],\n",
       "       [ 1.41304503,  1.58200646,  0.79882862, ...,  0.61012728,\n",
       "         1.78160888,  0.90911166]], shape=(400, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5621cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b353a04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 7), (80, 7), (320,), (80,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63149351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18c8f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\Advance-Deep-Learning\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation='relu',input_dim=7))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b9cf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93</span> (372.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93\u001b[0m (372.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93</span> (372.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93\u001b[0m (372.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3795b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.3817 - val_accuracy: 0.0000e+00 - val_loss: 0.2920\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.2369 - val_accuracy: 0.0000e+00 - val_loss: 0.2145\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1755 - val_accuracy: 0.0000e+00 - val_loss: 0.1699\n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1433 - val_accuracy: 0.0000e+00 - val_loss: 0.1466\n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1244 - val_accuracy: 0.0000e+00 - val_loss: 0.1299\n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1125 - val_accuracy: 0.0000e+00 - val_loss: 0.1183\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1027 - val_accuracy: 0.0000e+00 - val_loss: 0.1092\n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0938 - val_accuracy: 0.0000e+00 - val_loss: 0.1007\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0860 - val_accuracy: 0.0000e+00 - val_loss: 0.0917\n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0784 - val_accuracy: 0.0000e+00 - val_loss: 0.0860\n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0721 - val_accuracy: 0.0000e+00 - val_loss: 0.0799\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0662 - val_accuracy: 0.0000e+00 - val_loss: 0.0735\n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0607 - val_accuracy: 0.0000e+00 - val_loss: 0.0671\n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0558 - val_accuracy: 0.0000e+00 - val_loss: 0.0622\n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0514 - val_accuracy: 0.0000e+00 - val_loss: 0.0569\n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0473 - val_accuracy: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0437 - val_accuracy: 0.0000e+00 - val_loss: 0.0490\n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0404 - val_accuracy: 0.0000e+00 - val_loss: 0.0454\n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0372 - val_accuracy: 0.0000e+00 - val_loss: 0.0429\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0345 - val_accuracy: 0.0000e+00 - val_loss: 0.0393\n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0320 - val_accuracy: 0.0000e+00 - val_loss: 0.0369\n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0296 - val_accuracy: 0.0000e+00 - val_loss: 0.0345\n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0276 - val_accuracy: 0.0000e+00 - val_loss: 0.0322\n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0256 - val_accuracy: 0.0000e+00 - val_loss: 0.0299\n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0237 - val_accuracy: 0.0000e+00 - val_loss: 0.0286\n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0221 - val_accuracy: 0.0000e+00 - val_loss: 0.0274\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0206 - val_accuracy: 0.0000e+00 - val_loss: 0.0249\n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0194 - val_accuracy: 0.0000e+00 - val_loss: 0.0241\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0180 - val_accuracy: 0.0000e+00 - val_loss: 0.0226\n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0170 - val_accuracy: 0.0000e+00 - val_loss: 0.0212\n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0160 - val_accuracy: 0.0000e+00 - val_loss: 0.0204\n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0150 - val_accuracy: 0.0000e+00 - val_loss: 0.0192\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0143 - val_accuracy: 0.0000e+00 - val_loss: 0.0187\n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0136 - val_accuracy: 0.0000e+00 - val_loss: 0.0179\n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0129 - val_accuracy: 0.0000e+00 - val_loss: 0.0171\n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0124 - val_accuracy: 0.0000e+00 - val_loss: 0.0164\n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0119 - val_accuracy: 0.0000e+00 - val_loss: 0.0160\n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0114 - val_accuracy: 0.0000e+00 - val_loss: 0.0153\n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0110 - val_accuracy: 0.0000e+00 - val_loss: 0.0148\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0106 - val_accuracy: 0.0000e+00 - val_loss: 0.0144\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0102 - val_accuracy: 0.0000e+00 - val_loss: 0.0138\n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0099 - val_accuracy: 0.0000e+00 - val_loss: 0.0133\n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0096 - val_accuracy: 0.0000e+00 - val_loss: 0.0130\n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0093 - val_accuracy: 0.0000e+00 - val_loss: 0.0124\n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0090 - val_accuracy: 0.0000e+00 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0088 - val_accuracy: 0.0000e+00 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0086 - val_accuracy: 0.0000e+00 - val_loss: 0.0115\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0084 - val_accuracy: 0.0000e+00 - val_loss: 0.0111\n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 0.0109\n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0081 - val_accuracy: 0.0000e+00 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 0.0104\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0078 - val_accuracy: 0.0000e+00 - val_loss: 0.0102\n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 0.0100\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0075 - val_accuracy: 0.0000e+00 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0074 - val_accuracy: 0.0000e+00 - val_loss: 0.0095\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0073 - val_accuracy: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0071 - val_accuracy: 0.0000e+00 - val_loss: 0.0091\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 0.0085\n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0067 - val_accuracy: 0.0000e+00 - val_loss: 0.0084\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 0.0082\n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 0.0080\n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0064 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0063 - val_accuracy: 0.0000e+00 - val_loss: 0.0079\n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0062 - val_accuracy: 0.0000e+00 - val_loss: 0.0077\n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0076\n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 0.0073\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0060 - val_accuracy: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0072\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0057 - val_accuracy: 0.0000e+00 - val_loss: 0.0070\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0056 - val_accuracy: 0.0000e+00 - val_loss: 0.0068\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 0.0067\n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0054 - val_accuracy: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0053 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0052 - val_accuracy: 0.0000e+00 - val_loss: 0.0063\n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0062\n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0051 - val_accuracy: 0.0000e+00 - val_loss: 0.0061\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0060\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0060\n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0059\n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0050 - val_accuracy: 0.0000e+00 - val_loss: 0.0059\n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0058\n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0058\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0056\n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0056\n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0055\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0049 - val_accuracy: 0.0000e+00 - val_loss: 0.0055\n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0055\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0048 - val_accuracy: 0.0000e+00 - val_loss: 0.0054\n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0053\n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0052\n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0052\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0047 - val_accuracy: 0.0000e+00 - val_loss: 0.0052\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3569cb",
   "metadata": {},
   "source": [
    "In any kind of Online Judge a Jugde Engine is the heart of the computation. It is used for compile, execute & evaluate the submitted program by user in certain constrain such as imput size, time & memory. A system like UVA Online Judge and SPOJ build the pipeline - source code submission, compilation, execution against predefined test cases and lastly return verdict like on test cases like Accepted Not Accpeted. \n",
    "A key evaluation in Judge engine is to use Sandbox execution with Multithreaded worker architectures. A single thread worker can't handle large number of submission to solve this issure modern system adapt worker pools in each submission is dispatched process. These workers proceed in sandbox architecture like - chroot jails, cgroup or containerization architecture like dockers to provide security, CPU limitations , isolation.\n",
    "Those features enables qualityfull feedback while preserving the deterministic and reproducable execution. Though a lot of platforms still treat feedback as an auxilliary features rather than a first class design goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b8daa",
   "metadata": {},
   "source": [
    "Plagiarism detection in programming thorughly studied from simple structure to deep algorithm. Among those, MOSS remains the most widely adapted techniques. A fingerprint techniques designed for document or code similarity detection.\n",
    "MOSS underlying uses winnowing algorithm, which operates by tokenizing source code, K-Grams, Hashing them and selecting the subset of hash using sliding window. Unlike naive string matching, winnowing is robust against common evasion type such as variable renaming, comment delete. Winnowing achieves a quite good balance between sensitiity and scalability.\n",
    "A lot of alternatives are available such as AST( Abstract syntax tree ), neural embeddings graphs. Those algorithm can capture higher semantic similarity but need a handfull of computational cost.\n",
    "Thus, MOSS and winnowing remain dominant in real world systems with transparency and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06a78bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad959f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7307586687476813"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5d76b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28cff4263d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
